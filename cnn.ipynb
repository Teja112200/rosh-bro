{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m balanced_accuracy_score \u001b[39mas\u001b[39;00m BAS\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m---> 16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfa\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvis_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_model\n\u001b[0;32m     19\u001b[0m \u001b[39m# from tensorflow import keras\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[39m#  from tensorflow.keras import Sequential, Input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m# from tensorflow.keras.callbacks import EarlyStopping\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m# from tensorflow.keras.applications.inception_v3 import InceptionV3\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow_addons\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Useful extra functionality for TensorFlow maintained by SIG-addons.\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensure_tf_install\u001b[39;00m \u001b[39mimport\u001b[39;00m _check_tf_version\n\u001b[1;32m---> 18\u001b[0m _check_tf_version()\n\u001b[0;32m     20\u001b[0m \u001b[39m# Local project imports\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:36\u001b[0m, in \u001b[0;36m_check_tf_version\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_tf_version\u001b[39m():\n\u001b[0;32m     30\u001b[0m     \u001b[39m\"\"\"Warn the user if the version of TensorFlow used is not supported.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[39m    This is not a check for custom ops compatibility. This check only ensure that\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m    we support this TensorFlow version if the user uses only Addons' Python code.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdev\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39;49m__version__:\n\u001b[0;32m     37\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     38\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou are currently using a nightly version of TensorFlow (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTensorFlow Addons offers no support for the nightly versions of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m         )\n\u001b[0;32m     45\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from distutils.dir_util import copy_tree, remove_tree\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef as MCC\n",
    "from sklearn.metrics import balanced_accuracy_score as BAS\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# from tensorflow import keras\n",
    "\n",
    "#  from tensorflow.keras import Sequential, Input\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.layers import Conv2D, Flatten\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "from keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "base_dir = \"../input/alzheimer/Alzheimer_s Dataset\"\n",
    "root_dir = \"./\"\n",
    "test_dir = \"../input/alzheimer/Alzheimer_s Dataset/test/\"\n",
    "train_dir=\"../input/alzheimer/Alzheimer_s Dataset/train/\"\n",
    "work_dir = root_dir + \"dataset/\"\n",
    "if os.path.exists(work_dir):\n",
    "    remove_tree(work_dir)\n",
    "os.mkdir(work_dir)\n",
    "copy_tree(train_dir, work_dir)\n",
    "copy_tree(test_dir, work_dir)\n",
    "print(\"Working Directory Contents:\", os.listdir(work_dir))\n",
    "WORK_DIR = './dataset/'\n",
    "CLASSES = [ 'NonDemented','VeryMildDemented','MildDemented','ModerateDemented']\n",
    "IMG_SIZE = 176\n",
    "IMAGE_SIZE = [176, 176]\n",
    "DIM = (IMG_SIZE, IMG_SIZE)\n",
    "#Performing Image Augmentation to have more data samples\n",
    "\n",
    "\n",
    "ZOOM = [.99, 1.01]\n",
    "BRIGHT_RANGE = [0.8, 1.2]\n",
    "HORZ_FLIP = True\n",
    "FILL_MODE = \"constant\"\n",
    "DATA_FORMAT = \"channels_last\"\n",
    "work_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n",
    "train_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=False)\n",
    "def show_images(generator,y_pred=None):\n",
    "    \"\"\"\n",
    "    Input: An image generator,predicted labels (optional)\n",
    "    Output: Displays a grid of 9 images with lables\n",
    "    \"\"\"\n",
    "    # get image lables\n",
    "    labels =dict(zip([0,1,2,3], CLASSES))\n",
    "    # get a batch of images\n",
    "    x,y = generator.next()\n",
    "    # display a grid of 9 images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if y_pred is None:\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            idx = randint(0, 6400)\n",
    "            plt.imshow(x[idx])\n",
    "\n",
    "\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n",
    "    else:\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(x[i])\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n",
    "# Display Train Images\n",
    "show_images(train_data_gen)\n",
    "#Retrieving the data from the ImageDataGenerator iterator\n",
    "train_data, train_labels = train_data_gen.next()\n",
    "#Getting to know the dimensions of our dataset\n",
    "print(train_data.shape, train_labels.shape)\n",
    "#Performing over-sampling of the data, since the classes are imbalanced\n",
    "sm = SMOTE(random_state=42)\n",
    "train_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n",
    "train_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "print(train_data.shape, train_labels.shape)\n",
    "#Splitting the data into train, test, and validation sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "def conv_block(filters, act='relu'):\n",
    "    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n",
    "    block = Sequential()\n",
    "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
    "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
    "    block.add(BatchNormalization())\n",
    "    block.add(MaxPool2D())\n",
    "    return block\n",
    "def dense_block(units, dropout_rate, act='relu'):\n",
    "    \"\"\"Defining a Dense NN block for a Sequential CNN model. \"\"\"\n",
    "    block = Sequential()\n",
    "    block.add(Dense(units, activation=act))\n",
    "    block.add(BatchNormalization())\n",
    "    block.add(Dropout(dropout_rate))\n",
    "    return block\n",
    "def construct_model(act='relu'):\n",
    "    \"\"\"Constructing a Sequential CNN architecture for performing the classification task. \"\"\"\n",
    "    model = Sequential([\n",
    "    Input(shape=(*IMAGE_SIZE, 3)),\n",
    "    Conv2D(16, 3, activation=act, padding='same'),\n",
    "    Conv2D(16, 3, activation=act, padding='same'),\n",
    "    MaxPool2D(),\n",
    "\n",
    "    conv_block(32),\n",
    "    conv_block(64),\n",
    "    conv_block(128),\n",
    "    Dropout(0.2),\n",
    "    conv_block(256),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    dense_block(512, 0.7),\n",
    "    dense_block(128, 0.5),\n",
    "    dense_block(64, 0.3),\n",
    "    Dense(4, activation='softmax')\n",
    "    ], name = \"cnn_model\")\n",
    "    return model\n",
    "#Defining a custom callback function to stop training our model when accuracy goes above 99%\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_acc') > 0.99:\n",
    "            print(\"\\nReached accuracy threshold! Terminating training.\")\n",
    "            self.model.stop_training = True\n",
    "my_callback = MyCallback()\n",
    "#EarlyStopping callback to make sure model is always learning\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "#Defining other parameters for our CNN model\n",
    "\n",
    "model = construct_model()\n",
    "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "tf.keras.metrics.AUC(name='auc'),\n",
    "tfa.metrics.F1Score(num_classes=4)]\n",
    "CALLBACKS = [my_callback]\n",
    "model.compile(optimizer='adam',\n",
    "loss=tf.losses.CategoricalCrossentropy(),\n",
    "metrics=METRICS)\n",
    "model.summary()\n",
    "#Fit the training data to the model and validate it using the validation data\n",
    "EPOCHS = 50\n",
    "history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)\n",
    "#Plotting the trend of the metrics during training\n",
    "fig, ax = plt.subplots(1, 3, figsize = (30, 5))\n",
    "ax = ax.ravel()\n",
    "for i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n",
    "    ax[i].plot(history.history[metric])\n",
    "    ax[i].plot(history.history[\"val_\" + metric])\n",
    "    ax[i].set_title(\"Model {}\".format(metric))\n",
    "    ax[i].set_xlabel(\"Epochs\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])\n",
    "#Evaluating the model on the data\n",
    "\n",
    "#train_scores = model.evaluate(train_data, train_labels)\n",
    "#val_scores = model.evaluate(val_data, val_labels)\n",
    "test_scores = model.evaluate(test_data, test_labels)\n",
    "#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n",
    "#print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\n",
    "print(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))\n",
    "#Predicting the test data\n",
    "pred_labels = model.predict(test_data)\n",
    "#Print the classification report of the tested data\n",
    "#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n",
    "#similar to the test_labels\n",
    "def roundoff(arr):\n",
    "    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n",
    "    arr[np.argwhere(arr != arr.max())] = 0\n",
    "    arr[np.argwhere(arr == arr.max())] = 1\n",
    "    return arr\n",
    "for labels in pred_labels:\n",
    "    labels = roundoff(labels)\n",
    "print(classification_report(test_labels, pred_labels, target_names=CLASSES))\n",
    "#Plot the confusion matrix to understand the classification in detail\n",
    "pred_ls = np.argmax(pred_labels, axis=1)\n",
    "test_ls = np.argmax(test_labels, axis=1)\n",
    "conf_arr = confusion_matrix(test_ls, pred_ls)\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "plt.title('Alzheimer\\'s Disease Diagnosis')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')\n",
    "plt.show(ax)\n",
    "#Printing some other classification metrics\n",
    "print(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\n",
    "print(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))\n",
    "#Saving the model for future use\n",
    "pickle.dump(model, open('alzheimer_model.pkl', 'wb'))\n",
    "pretrained_model = tf.keras.models.load_model(model_dir)\n",
    "#Check its architecture\n",
    "plot_model(pretrained_model, to_file=work_dir + \"model_plot.png\", show_shapes=True, show_layer_names=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d59e3218b14985d44cade909fca4d2dc46a450ba0bf1d6f947190146364268a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
